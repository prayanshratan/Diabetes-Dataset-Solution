{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: seaborn in /home/prayansh/anaconda3/lib/python3.6/site-packages (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.0.1 in /home/prayansh/anaconda3/lib/python3.6/site-packages (from seaborn) (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.22.0 in /home/prayansh/.local/lib/python3.6/site-packages (from seaborn) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /home/prayansh/.local/lib/python3.6/site-packages (from seaborn) (1.16.3)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.2 in /home/prayansh/anaconda3/lib/python3.6/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /home/prayansh/.local/lib/python3.6/site-packages (from pandas>=0.22.0->seaborn) (2019.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /home/prayansh/.local/lib/python3.6/site-packages (from pandas>=0.22.0->seaborn) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/prayansh/anaconda3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /home/prayansh/anaconda3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /home/prayansh/anaconda3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/prayansh/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.22.0->seaborn) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/prayansh/anaconda3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn) (40.6.3)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U seaborn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>146</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>160</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>150</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9</td>\n",
       "      <td>140</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>13</td>\n",
       "      <td>153</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>140</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6</td>\n",
       "      <td>162</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8</td>\n",
       "      <td>154</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7</td>\n",
       "      <td>137</td>\n",
       "      <td>90</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg  plas  pres  skin  insu  mass   pedi  age            class\n",
       "0       6   148    72    35     0  33.6  0.627   50  tested_positive\n",
       "1       1    85    66    29     0  26.6  0.351   31  tested_negative\n",
       "2       8   183    64     0     0  23.3  0.672   32  tested_positive\n",
       "3       1    89    66    23    94  28.1  0.167   21  tested_negative\n",
       "4       0   137    40    35   168  43.1  2.288   33  tested_positive\n",
       "5       5   116    74     0     0  25.6  0.201   30  tested_negative\n",
       "6       3    78    50    32    88  31.0  0.248   26  tested_positive\n",
       "7      10   115     0     0     0  35.3  0.134   29  tested_negative\n",
       "8       2   197    70    45   543  30.5  0.158   53  tested_positive\n",
       "9       8   125    96     0     0   0.0  0.232   54  tested_positive\n",
       "10      4   110    92     0     0  37.6  0.191   30  tested_negative\n",
       "11     10   168    74     0     0  38.0  0.537   34  tested_positive\n",
       "12     10   139    80     0     0  27.1  1.441   57  tested_negative\n",
       "13      1   189    60    23   846  30.1  0.398   59  tested_positive\n",
       "14      5   166    72    19   175  25.8  0.587   51  tested_positive\n",
       "15      7   100     0     0     0  30.0  0.484   32  tested_positive\n",
       "16      0   118    84    47   230  45.8  0.551   31  tested_positive\n",
       "17      7   107    74     0     0  29.6  0.254   31  tested_positive\n",
       "18      1   103    30    38    83  43.3  0.183   33  tested_negative\n",
       "19      1   115    70    30    96  34.6  0.529   32  tested_positive\n",
       "20      3   126    88    41   235  39.3  0.704   27  tested_negative\n",
       "21      8    99    84     0     0  35.4  0.388   50  tested_negative\n",
       "22      7   196    90     0     0  39.8  0.451   41  tested_positive\n",
       "23      9   119    80    35     0  29.0  0.263   29  tested_positive\n",
       "24     11   143    94    33   146  36.6  0.254   51  tested_positive\n",
       "25     10   125    70    26   115  31.1  0.205   41  tested_positive\n",
       "26      7   147    76     0     0  39.4  0.257   43  tested_positive\n",
       "27      1    97    66    15   140  23.2  0.487   22  tested_negative\n",
       "28     13   145    82    19   110  22.2  0.245   57  tested_negative\n",
       "29      5   117    92     0     0  34.1  0.337   38  tested_negative\n",
       "..    ...   ...   ...   ...   ...   ...    ...  ...              ...\n",
       "738     2    99    60    17   160  36.6  0.453   21  tested_negative\n",
       "739     1   102    74     0     0  39.5  0.293   42  tested_positive\n",
       "740    11   120    80    37   150  42.3  0.785   48  tested_positive\n",
       "741     3   102    44    20    94  30.8  0.400   26  tested_negative\n",
       "742     1   109    58    18   116  28.5  0.219   22  tested_negative\n",
       "743     9   140    94     0     0  32.7  0.734   45  tested_positive\n",
       "744    13   153    88    37   140  40.6  1.174   39  tested_negative\n",
       "745    12   100    84    33   105  30.0  0.488   46  tested_negative\n",
       "746     1   147    94    41     0  49.3  0.358   27  tested_positive\n",
       "747     1    81    74    41    57  46.3  1.096   32  tested_negative\n",
       "748     3   187    70    22   200  36.4  0.408   36  tested_positive\n",
       "749     6   162    62     0     0  24.3  0.178   50  tested_positive\n",
       "750     4   136    70     0     0  31.2  1.182   22  tested_positive\n",
       "751     1   121    78    39    74  39.0  0.261   28  tested_negative\n",
       "752     3   108    62    24     0  26.0  0.223   25  tested_negative\n",
       "753     0   181    88    44   510  43.3  0.222   26  tested_positive\n",
       "754     8   154    78    32     0  32.4  0.443   45  tested_positive\n",
       "755     1   128    88    39   110  36.5  1.057   37  tested_positive\n",
       "756     7   137    90    41     0  32.0  0.391   39  tested_negative\n",
       "757     0   123    72     0     0  36.3  0.258   52  tested_positive\n",
       "758     1   106    76     0     0  37.5  0.197   26  tested_negative\n",
       "759     6   190    92     0     0  35.5  0.278   66  tested_positive\n",
       "760     2    88    58    26    16  28.4  0.766   22  tested_negative\n",
       "761     9   170    74    31     0  44.0  0.403   43  tested_positive\n",
       "762     9    89    62     0     0  22.5  0.142   33  tested_negative\n",
       "763    10   101    76    48   180  32.9  0.171   63  tested_negative\n",
       "764     2   122    70    27     0  36.8  0.340   27  tested_negative\n",
       "765     5   121    72    23   112  26.2  0.245   30  tested_negative\n",
       "766     1   126    60     0     0  30.1  0.349   47  tested_positive\n",
       "767     1    93    70    31     0  30.4  0.315   23  tested_negative\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv('diabetes.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>146</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>160</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>150</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9</td>\n",
       "      <td>140</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>13</td>\n",
       "      <td>153</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>140</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6</td>\n",
       "      <td>162</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8</td>\n",
       "      <td>154</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7</td>\n",
       "      <td>137</td>\n",
       "      <td>90</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg  plas  pres  skin  insu  mass   pedi  age  class\n",
       "0       6   148    72    35     0  33.6  0.627   50      1\n",
       "1       1    85    66    29     0  26.6  0.351   31      0\n",
       "2       8   183    64     0     0  23.3  0.672   32      1\n",
       "3       1    89    66    23    94  28.1  0.167   21      0\n",
       "4       0   137    40    35   168  43.1  2.288   33      1\n",
       "5       5   116    74     0     0  25.6  0.201   30      0\n",
       "6       3    78    50    32    88  31.0  0.248   26      1\n",
       "7      10   115     0     0     0  35.3  0.134   29      0\n",
       "8       2   197    70    45   543  30.5  0.158   53      1\n",
       "9       8   125    96     0     0   0.0  0.232   54      1\n",
       "10      4   110    92     0     0  37.6  0.191   30      0\n",
       "11     10   168    74     0     0  38.0  0.537   34      1\n",
       "12     10   139    80     0     0  27.1  1.441   57      0\n",
       "13      1   189    60    23   846  30.1  0.398   59      1\n",
       "14      5   166    72    19   175  25.8  0.587   51      1\n",
       "15      7   100     0     0     0  30.0  0.484   32      1\n",
       "16      0   118    84    47   230  45.8  0.551   31      1\n",
       "17      7   107    74     0     0  29.6  0.254   31      1\n",
       "18      1   103    30    38    83  43.3  0.183   33      0\n",
       "19      1   115    70    30    96  34.6  0.529   32      1\n",
       "20      3   126    88    41   235  39.3  0.704   27      0\n",
       "21      8    99    84     0     0  35.4  0.388   50      0\n",
       "22      7   196    90     0     0  39.8  0.451   41      1\n",
       "23      9   119    80    35     0  29.0  0.263   29      1\n",
       "24     11   143    94    33   146  36.6  0.254   51      1\n",
       "25     10   125    70    26   115  31.1  0.205   41      1\n",
       "26      7   147    76     0     0  39.4  0.257   43      1\n",
       "27      1    97    66    15   140  23.2  0.487   22      0\n",
       "28     13   145    82    19   110  22.2  0.245   57      0\n",
       "29      5   117    92     0     0  34.1  0.337   38      0\n",
       "..    ...   ...   ...   ...   ...   ...    ...  ...    ...\n",
       "738     2    99    60    17   160  36.6  0.453   21      0\n",
       "739     1   102    74     0     0  39.5  0.293   42      1\n",
       "740    11   120    80    37   150  42.3  0.785   48      1\n",
       "741     3   102    44    20    94  30.8  0.400   26      0\n",
       "742     1   109    58    18   116  28.5  0.219   22      0\n",
       "743     9   140    94     0     0  32.7  0.734   45      1\n",
       "744    13   153    88    37   140  40.6  1.174   39      0\n",
       "745    12   100    84    33   105  30.0  0.488   46      0\n",
       "746     1   147    94    41     0  49.3  0.358   27      1\n",
       "747     1    81    74    41    57  46.3  1.096   32      0\n",
       "748     3   187    70    22   200  36.4  0.408   36      1\n",
       "749     6   162    62     0     0  24.3  0.178   50      1\n",
       "750     4   136    70     0     0  31.2  1.182   22      1\n",
       "751     1   121    78    39    74  39.0  0.261   28      0\n",
       "752     3   108    62    24     0  26.0  0.223   25      0\n",
       "753     0   181    88    44   510  43.3  0.222   26      1\n",
       "754     8   154    78    32     0  32.4  0.443   45      1\n",
       "755     1   128    88    39   110  36.5  1.057   37      1\n",
       "756     7   137    90    41     0  32.0  0.391   39      0\n",
       "757     0   123    72     0     0  36.3  0.258   52      1\n",
       "758     1   106    76     0     0  37.5  0.197   26      0\n",
       "759     6   190    92     0     0  35.5  0.278   66      1\n",
       "760     2    88    58    26    16  28.4  0.766   22      0\n",
       "761     9   170    74    31     0  44.0  0.403   43      1\n",
       "762     9    89    62     0     0  22.5  0.142   33      0\n",
       "763    10   101    76    48   180  32.9  0.171   63      0\n",
       "764     2   122    70    27     0  36.8  0.340   27      0\n",
       "765     5   121    72    23   112  26.2  0.245   30      0\n",
       "766     1   126    60     0     0  30.1  0.349   47      1\n",
       "767     1    93    70    31     0  30.4  0.315   23      0\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat= data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "num= LabelEncoder()\n",
    "dat['class']= num.fit_transform(dat['class'].astype('str'))\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             preg        plas        pres        skin        insu        mass  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "             pedi         age       class  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat['preg']=dat['preg'].replace(0,dat['preg'].mean())\n",
    "# dat['plas']=dat['plas'].replace(0,dat['plas'].mean())\n",
    "# dat['pres']=dat['pres'].replace(0,dat['pres'].mean())\n",
    "# dat['skin']=dat['skin'].replace(0,dat['skin'].mean())\n",
    "# dat['insu']=dat['insu'].replace(0,dat['insu'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= dat['class']\n",
    "dat= dat.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dat, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prayansh/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.6341463414634146, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.6634146341463415, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.6536585365853659, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.7156862745098039, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.6195121951219512, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.6292682926829268, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.6519607843137255, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.7073170731707317, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.7219512195121951, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.7156862745098039, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.7317073170731707, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.775609756097561, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.7205882352941176, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.6146341463414634, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.6341463414634146, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.6274509803921569, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.697560975609756, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.7121951219512195, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.7009803921568627, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.7463414634146341, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.7707317073170732, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.7205882352941176, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.6146341463414634, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.6341463414634146, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.6274509803921569, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.6634146341463415, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.6682926829268293, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.6568627450980392, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.697560975609756, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.7170731707317073, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.7107843137254902, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.6146341463414634, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.6341463414634146, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.6274509803921569, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.6487804878048781, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.6731707317073171, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.6372549019607843, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.697560975609756, total=   0.1s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.7170731707317073, total=   0.1s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.7107843137254902, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "\t\t\t'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "\t\t\t'kernel': ['rbf']} \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "\n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "\n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       107\n",
      "           1       0.76      0.60      0.67        47\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       154\n",
      "   macro avg       0.80      0.76      0.77       154\n",
      "weighted avg       0.81      0.82      0.81       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data3= dat\n",
    "# data3['insu']=data3['insu'].replace(0,data3['insu'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prayansh/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/prayansh/.local/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/prayansh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train_std=sc.fit_transform(X_train)\n",
    "X_validation_std=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prayansh/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.7073170731707317, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.7170731707317073, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.7009803921568627, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.6487804878048781, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.6878048780487804, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.6617647058823529, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.7414634146341463, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.7853658536585366, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.7303921568627451, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.751219512195122, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.7902439024390244, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.7549019607843137, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.6634146341463415, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.6780487804878049, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.6323529411764706, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.7121951219512195, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.7804878048780488, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.7303921568627451, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.751219512195122, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.7609756097560976, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ......... C=10, gamma=0.01, kernel=rbf, score=0.75, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.751219512195122, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.7853658536585366, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ........ C=10, gamma=0.001, kernel=rbf, score=0.75, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.6390243902439025, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.6421568627450981, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.6634146341463415, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.6780487804878049, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.6323529411764706, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.6780487804878049, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.6926829268292682, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.6764705882352942, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.7414634146341463, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.7609756097560976, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.7303921568627451, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.7707317073170732, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.7609756097560976, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.7598039215686274, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.7560975609756098, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.7853658536585366, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ...... C=100, gamma=0.0001, kernel=rbf, score=0.75, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.6634146341463415, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.6780487804878049, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.6323529411764706, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.6829268292682927, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.6780487804878049, total=   0.1s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.6519607843137255, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.7268292682926829, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.7414634146341463, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.7205882352941176, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.7609756097560976, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.7658536585365854, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.7598039215686274, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.7658536585365854, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.7609756097560976, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.7549019607843137, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "\t\t\t'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "\t\t\t'kernel': ['rbf']} \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "\n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train_std, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       107\n",
      "           1       0.76      0.62      0.68        47\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       154\n",
      "   macro avg       0.80      0.77      0.78       154\n",
      "weighted avg       0.82      0.82      0.82       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_validation_std) \n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8246753246753247\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary modules \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import load_iris \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# irisData = load_iris() \n",
    "\n",
    "# Create feature and target arrays \n",
    "X = dat \n",
    " \n",
    "\n",
    "# Split into training and test set \n",
    "# X_train_k2, X_test_k2, y_train, y_test = train_test_split( \n",
    "# \t\t\tX, y, test_size = 0.2, random_state=42) \n",
    "\n",
    "neighbors = np.arange(1, 9) \n",
    "train_accuracy = np.empty(len(neighbors)) \n",
    "test_accuracy = np.empty(len(neighbors)) \n",
    "\n",
    "# Loop over K values \n",
    "for i, k in enumerate(neighbors): \n",
    "\tknn = KNeighborsClassifier(n_neighbors=k) \n",
    "\tknn.fit(X_train_std, y_train) \n",
    "\t\n",
    "\t# Compute traning and test data accuracy \n",
    "\ttrain_accuracy[i] = knn.score(X_train_std, y_train) \n",
    "\ttest_accuracy[i] = knn.score(X_validation_std, y_test) \n",
    "\n",
    "# Generate plot \n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing dataset Accuracy') \n",
    "plt.plot(neighbors, train_accuracy, label = 'Training dataset Accuracy') \n",
    "\n",
    "plt.legend() \n",
    "plt.xlabel('n_neighbors') \n",
    "plt.ylabel('Accuracy') \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
